---
title: "Cross-validation and bootstrap"
author: "Mark Goldberg"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
draft: false
math: false
tags: ["R", "Statistics", "Cross-validation", "Bootstrap"]
categories: ["Statistics"]
#bibliography: [bib.bib]
output:
  blogdown::html_page:
    toc: true
---

From the following examples we will learn:
1.
2.
3.
Model: linear regression, kNN
Dataset: Auto {ISLR}

В практических примерах ниже показано:   

* как оценить точность модели методом перекрёстной выборки;    
* методом проверочной выборки;    
* методом перекрёстной проверки по отдельным наблюдениям (LOOCV);   
* методом k-кратной перекрёстной проверки;   
* как применять бутстреп для оценки точности статистического параметра и оценок параметров модели   


*Модели*: линейная регрессия, kNN.   
*Данные*: `Auto {ISLR}`   


```{r, echo = T, results = "hide"}
library('ISLR')        # datasets Auto
library('GGally')      # matrix diagrams
library('boot') 		   # cross-validation
```

```{r}
# data exploration
head(Auto)
str(Auto)
```
You can check correlation of various parameters using
`ggpairs(Auto[, -9])`

We will check the correlation between mpg ~ horsepower
```{r}
plot(Auto$horsepower, Auto$mpg,
     xlab = 'horsepower', ylab = 'mpg',
     pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4),
     bg = rgb(0, 0, 1, alpha = 0.4))
```

## Cross validation

```{r}



```

## Validation sample 
Split data to train and test sets and build model using train data.

```{r}
n <- nrow(Auto)                  # number of observation
train.percent <- 0.5             # portion of train data
attach(Auto)                     # to call mpg & horsepower instead of Auto$mpg & Auto$horsepower

# split data into train and test
set.seed(1)
inTrain <- sample(n, n * train.percent)

# plot train data
plot(horsepower[inTrain], mpg[inTrain],
     xlab = 'horsepower', ylab = 'mpg', pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
# add test data
points(horsepower[-inTrain], mpg[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4))
legend('topright', pch = c(16, 16), col = c('blue', 'red'), legend = c('test', 'train'))
```

Build models for validataion of accuracy:   
$$
\hat{mpg} = f(horsepower)
$$
**Linear model**: $\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower$.  

``` {r}
# fit linear model for train data
fit.lm.1 <- lm(mpg ~ horsepower, subset = inTrain)

# MSE of test data
mean((mpg[-inTrain] - predict(fit.lm.1, Auto[-inTrain, ]))^2)
```

```{r echo = F}
err.test <- mean((mpg[-inTrain] - predict(fit.lm.1, Auto[-inTrain, ]))^2)
names(err.test) <- 1
```

Строим **квадратичную модель**: $\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2$.   

```{r}
# присоединить таблицу с данными: названия стоблцов будут доступны напрямую
attach(Auto)
# подгонка линейной модели на обучающей выборке
fit.lm.2 <- lm(mpg ~ poly(horsepower, 2), 
               subset = inTrain)
# считаем MSE на тестовой выборке
mean((mpg[-inTrain] - predict(fit.lm.2,
                              Auto[-inTrain, ]))^2)
# отсоединить таблицу с данными
detach(Auto)
```

```{r echo = F}
err.test <- c(err.test, 
              mean((Auto$mpg[-inTrain] - predict(fit.lm.2,
                                                 Auto[-inTrain, ]))^2))
names(err.test)[length(err.test)] <- 2
```

Строим **кубическую модель**: $\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2 + \hat{\beta}_3 \cdot horsepower^3$.   

```{r}
# присоединить таблицу с данными: названия стоблцов будут доступны напрямую
attach(Auto)
# подгонка линейной модели на обучающей выборке
fit.lm.3 <- lm(mpg ~ poly(horsepower, 3), 
               subset = inTrain)
# считаем MSE на тестовой выборке
mean((mpg[-inTrain] - predict(fit.lm.3,
                              Auto[-inTrain, ]))^2)
# отсоединить таблицу с данными
detach(Auto)
```

```{r echo = F}
err.test <- c(err.test, 
              mean((Auto$mpg[-inTrain] - predict(fit.lm.3,
                              Auto[-inTrain, ]))^2))
names(err.test)[length(err.test)] <- 3
```

### Перекрёстная проверка по отдельным наблюдениям (LOOCV)

Это самый затратный в вычислительном плане метод, но и самый надёжный в плане оценки ошибки вне выборки. Попробуем применить его к линейной модели.    

```{r}
# подгонка линейной модели на обучающей выборке
fit.glm <- glm(mpg ~ horsepower, data = Auto)
# считаем LOOCV-ошибку
cv.err <- cv.glm(Auto, fit.glm)
# результат: первое число -- по формуле LOOCV-ошибки,
#  второе -- с поправкой на смещение
cv.err$delta[1]
```  

Теперь оценим точность полиномиальных моделей, меняя степень, в которой стоит регрессор.   

```{r}
# вектор с LOOCV-ошибками
cv.err.loocv <- rep(0, 5)
names(cv.err.loocv) <- 1:5
# цикл по степеням полиномов
for (i in 1:5){
  fit.glm <- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.loocv[i] <- cv.glm(Auto, fit.glm)$delta[1]
}
# результат
cv.err.loocv
```


### k-кратная перекрёстная проверка

K-кратная кросс-валидация -- компромисс между методом проверочной выборки и LOOCV. Оценка ошибки вне выборки ближе к правде, по сравнению с проверочной выборкой, а объём вычислений меньше, чем при LOOCV. Проведём 10-кратную кросс-валидацию моделей разных степеней.     

```{r}
# оценим точность полиномиальных моделей, меняя степень
# вектор с ошибками по 10-кратной кросс-валидации
cv.err.k.fold <- rep(0, 5)
names(cv.err.k.fold) <- 1:5
# цикл по степеням полиномов
for (i in 1:5){
  fit.glm <- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.k.fold[i] <- cv.glm(Auto, fit.glm,
                             K = 10)$delta[1]
}
# результат
cv.err.k.fold
```

Для сравнения напомним результаты расчёта MSE методом проверочной выборки:   

```{r}
err.test
```


Опираясь на результаты расчётов с кросс-валидацией, можно заключить, что на самом деле ошибка вне выборки у линейной модели выше, чем показывала MSE на тестовой выборке. А модели со степенями 2 и 3 на самом деле точнее, чем показывала MSE без перекрёстной проверки.   


## Бутстреп   

### Точность оценки статистичестического параметра   

Пример с инвестиционным портфелем из двух активов: `Portfolio {ISLR}`. В наборе данных две переменных: 
* `X` -- доход от актива X,   
* `Y` -- доход от актива Y.   
Портфель инвестиций состоит из активов $X$ и $Y$, долю актива $X$ обозначим как $\alpha$. Минимум дасперсии доходности: 

$$
\mathrm{Var}(\alpha X + (1 - \alpha) Y) \rightarrow \mathrm{min}
$$

-- достигается при значении параметра:  
$$
\alpha = \frac{\sigma_Y^2 - \sigma_{XY}}{\sigma_X^2 + \sigma_Y^2 - 2\sigma_{XY}}
$$
Данных для оценки $\hat{\sigma_X^2}$, $\hat{\sigma_Y^2}$ и $\hat{\sigma_{XY}}$ немного (100 наблюдений), поэтому применим бутстреп.   

```{r}
head(Portfolio)
str(Portfolio)
# функция для вычисления искомого параметра
alpha.fn <- function(data, index){
  X = data$X[index]
  Y = data$Y[index]
  (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2*cov(X, Y))
}
# рассчитать alpha по всем 100 наблюдениям
alpha.fn(Portfolio, 1:100)
# создать бутстреп-выборку и повторно вычислить alpha
set.seed(1)
alpha.fn(Portfolio, sample(100, 100, replace = T))
# теперь -- многократное повторение предыдущей операции
boot(Portfolio, alpha.fn, R = 1000)
```

Бутстреп повторяет расчёт параметра много раз, делая повторные выборки из наших 100 наблюдений. В итоге этим методом можно вычислить стандартную ошибку параметра, не опираясь на допущения о законе распределении параметра. В нашем случае $\alpha = 0.576$ со стандартной ошибкой $s_{\hat{\alpha}} = 0.089$.   

### Точность оценки параметра регрессии   

При построении модели регрессии проблемы в остатках приводят к неверной оценке ошибок параметров. Обойти эту проблему можно, применив для расчёта этих ошибок бутстреп.   

```{r}
# Оценивание точности линейной регрессионной модели ----------------------------
# оценить стандартные ошибки параметров модели 
#  mpg = beta_0 + beta_1 * horsepower с помощью бутстрепа,
#  сравнить с оценками ошибок по МНК
# функция для расчёта коэффициентов ПЛР по выборке из данных
boot.fn <- function(data, index){
  coef(lm(mpg ~ horsepower, data = data, subset = index))
}
boot.fn(Auto, 1:n)
# пример применения функции к бутстреп-выборке
set.seed(1)
boot.fn(Auto, sample(n, n, replace = T))
# применяем функцию boot для вычисления стандартных ошибок параметров
#  (1000 выборок с повторами)
boot(Auto, boot.fn, 1000)
# сравним с МНК
attach(Auto)
summary(lm(mpg ~ horsepower))$coef
detach(Auto)
# оценки отличаются из-за того, что МНК -- параметрический метод с допущениями
# вычислим оценки параметров квадратичной модели регрессии
boot.fn.2 <- function(data, index){
  coef(lm(mpg ~ poly(horsepower, 2), data = data, subset = index))
}
# применим функцию к 1000 бутсреп-выборкам
set.seed(1)
boot(Auto, boot.fn, 1000)
```

В модели регрессии, для которой проводился расчёт, похоже, не нарушаются требования к остаткам, и оценки стандартных ошибок параметров, рассчитанные по МНК, очень близки к ошибкам этих же параметров, полученных бутстрепом.   


*Источники*   

1. *James G., Witten D., Hastie T. and Tibshirani R.*  An Introduction to Statistical Learning with Applications in R. URL: [http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf)    

