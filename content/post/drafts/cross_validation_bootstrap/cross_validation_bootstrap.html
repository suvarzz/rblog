---
title: "Cross-validation and bootstrap"
author: "Mark Goldberg"
date: '2019-08-02'
draft: true
math: true
tags: ["R", "Statistics", "Cross-validation", "Bootstrap"]
categories: ["Statistics"]
#bibliography: [bib.bib]
output:
  blogdown::html_page:
    toc: true
summary: "From the following examples we will learn wow to estimate model precision by cross-validation, validation sample and leave-one-out cross-validation (LOOCV)."
---


<div id="TOC">
<ul>
<li><a href="#validation-sample">Validation sample</a></li>
<li><a href="#leave-one-out-cross-validation-loocv">Leave-one-out cross-validation (LOOCV)</a></li>
<li><a href="#k-cross-validation">k-cross-validation</a></li>
<li><a href="#bootstrap">Bootstrap</a><ul>
<li><a href="#presition-estimation-of-model-parameter">Presition estimation of model parameter</a></li>
<li><a href="#---">Точность оценки параметра регрессии</a></li>
</ul></li>
</ul>
</div>

<p>From the following examples we will learn wow to estimate model precision by cross-validation, validation sample and leave-one-out cross-validation (LOOCV).</p>
<p><em>Model</em>: linear regression, kNN <em>Dataset</em>: <code>Auto {ISLR}</code></p>
<p>We want to build models and compare this models:<br />
mpg ~ f(horsepower) <code>Auto</code> dataset, where<br />
<strong>mpg</strong> - miles per gallon<br />
<strong>horsepower</strong> - engine horsepower</p>
<pre class="r"><code>library(&#39;ISLR&#39;)        # datasets Auto
attach(Auto)</code></pre>
<pre class="r"><code>plot(horsepower, mpg,
     xlab = &#39;horsepower&#39;, ylab = &#39;mpg&#39;, pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4),
     bg = rgb(0, 0, 1, alpha = 0.4))</code></pre>
<p><img src="/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<div id="validation-sample" class="section level3">
<h3>Validation sample</h3>
<p>Split data to train and test sets and build model using train data.</p>
<p>Make random vector for data subsetting:</p>
<pre class="r"><code>n &lt;- nrow(Auto)         # number of observation
train.percent &lt;- 0.5    # portion of train data

# split data into train and test
set.seed(1)
inTrain &lt;- sample(n, n*train.percent)</code></pre>
<p>Plot data</p>
<pre class="r"><code># plot train data
par(mar = c(4, 4, 0.5, 1))
plot(horsepower[inTrain], mpg[inTrain],
     xlab = &#39;horsepower&#39;, ylab = &#39;mpg&#39;, pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
# add test data
points(horsepower[-inTrain], mpg[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4))
legend(&#39;topright&#39;, pch = c(16, 16), col = c(&#39;blue&#39;, &#39;red&#39;), legend = c(&#39;test&#39;, &#39;train&#39;))</code></pre>
<p><img src="/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Let’s buld models for train data using <strong>polynomial linear regression</strong> using vaious polinomial degrees and estimate MSE for each of these models using test data:<br />
1. <strong>Linear</strong>: <span class="math inline">\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower\)</span>.<br />
2. <strong>Squared</strong>: <span class="math inline">\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2\)</span>.<br />
3. <strong>Cubic</strong>: <span class="math inline">\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2 + \hat{\beta}_3 \cdot horsepower^3\)</span>.</p>
<pre class="r"><code>models &lt;- lapply(1:3, function(n) {
  fit.lm &lt;- lm(mpg ~ poly(horsepower, n), data=Auto, subset=inTrain)
  })

# keep MSE for each model
err.test &lt;- sapply(1:3, function(n) {
  mean((mpg[-inTrain] - predict(models[[n]], Auto[-inTrain, ]))^2)
})
names(err.test) &lt;- c(&#39;lm1&#39;, &#39;lm2&#39;, &#39;lm3&#39;)</code></pre>
<p>Q: Do our modeles fit the formulas shown before?</p>
<p>Plot models</p>
<pre class="r"><code>par(mar = c(4, 4, 0.5, 1))
plot(horsepower[inTrain], mpg[inTrain],
     xlab = &#39;horsepower&#39;, ylab = &#39;mpg&#39;, pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
# add test data
points(horsepower[-inTrain], mpg[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4))

colors=c(&#39;black&#39;, &#39;blue&#39;, &#39;red&#39;)
x1 &lt;- data.frame(horsepower=seq(min(horsepower), max(horsepower), length = 200))
for (i in 1:3) {
    y2 &lt;- predict(models[[i]], newdata=x1)
    lines(x1$horsepower, y2, col=colors[i], lwd=c(2,2,2))
}
legend(&#39;topright&#39;, lty=c(1,1,1),
       col = c(&#39;black&#39;, &#39;blue&#39;, &#39;red&#39;),
       legend = c(&#39;x&#39;, &#39;x^2&#39;, &#39;x^3&#39;), lwd=c(2,2,2))</code></pre>
<p><img src="/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="leave-one-out-cross-validation-loocv" class="section level3">
<h3>Leave-one-out cross-validation (LOOCV)</h3>
<pre class="r"><code>library(&#39;GGally&#39;)      # matrix diagrams
library(&#39;boot&#39;)        # cross-validation</code></pre>
<pre class="r"><code># fit model for train data
fit.glm &lt;- glm(mpg ~ horsepower, data = Auto)
# LOOCV-error
cv.err &lt;- cv.glm(Auto, fit.glm)
cv.err$delta[1]</code></pre>
<pre><code>## [1] 24.23151</code></pre>
<p>Estimate the precision of polynomial models by changing power.</p>
<pre class="r"><code># vector of LOOCV-errors
cv.err.loocv &lt;- rep(0, 5)
names(cv.err.loocv) &lt;- 1:5
# repeat by powers of polynomes
for (i in 1:5){
  fit.glm &lt;- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.loocv[i] &lt;- cv.glm(Auto, fit.glm)$delta[1]
}
# result
cv.err.loocv</code></pre>
<pre><code>##        1        2        3        4        5 
## 24.23151 19.24821 19.33498 19.42443 19.03321</code></pre>
</div>
<div id="k-cross-validation" class="section level3">
<h3>k-cross-validation</h3>
<p>K-times cross-validation is a compromize between sample validation and LOOCV. It is computationally more effective than LOOCV but not so presize.<br />
We will make 10-time validation.</p>
<pre class="r"><code>cv.err.k.fold &lt;- rep(0, 5)
names(cv.err.k.fold) &lt;- 1:5
# repeat for power of polynomes
for (i in 1:5){
  fit.glm &lt;- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.k.fold[i] &lt;- cv.glm(Auto, fit.glm,
                             K = 10)$delta[1]
}
# result
cv.err.k.fold</code></pre>
<pre><code>##        1        2        3        4        5 
## 24.19329 19.29416 19.49610 19.61828 19.15289</code></pre>
<p>Compare with previous result:</p>
<pre class="r"><code>err.test</code></pre>
<pre><code>##      lm1      lm2      lm3 
## 26.14142 19.82259 19.78252</code></pre>
<p>Опираясь на результаты расчётов с кросс-валидацией, можно заключить, что на самом деле ошибка вне выборки у линейной модели выше, чем показывала MSE на тестовой выборке. А модели со степенями 2 и 3 на самом деле точнее, чем показывала MSE без перекрёстной проверки.</p>
</div>
<div id="bootstrap" class="section level2">
<h2>Bootstrap</h2>
<div id="presition-estimation-of-model-parameter" class="section level3">
<h3>Presition estimation of model parameter</h3>
<p>Пример с инвестиционным портфелем из двух активов: <code>Portfolio {ISLR}</code>. В наборе данных две переменных: * <code>X</code> – income from X,<br />
* <code>Y</code> – income from Y.<br />
We have <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the portion of <span class="math inline">\(X\)</span> is <span class="math inline">\(\alpha\)</span>. Min of income dispersion:</p>
<p><span class="math display">\[
\mathrm{Var}(\alpha X + (1 - \alpha) Y) \rightarrow \mathrm{min}
\]</span></p>
<p>– parameter:<br />
<span class="math display">\[
\alpha = \frac{\sigma_Y^2 - \sigma_{XY}}{\sigma_X^2 + \sigma_Y^2 - 2\sigma_{XY}}
\]</span> Данных для оценки <span class="math inline">\(\hat{\sigma_X^2}\)</span>, <span class="math inline">\(\hat{\sigma_Y^2}\)</span> и <span class="math inline">\(\hat{\sigma_{XY}}\)</span> немного (100 наблюдений), поэтому применим бутстреп.</p>
<pre class="r"><code>head(Portfolio)</code></pre>
<pre><code>##            X          Y
## 1 -0.8952509 -0.2349235
## 2 -1.5624543 -0.8851760
## 3 -0.4170899  0.2718880
## 4  1.0443557 -0.7341975
## 5 -0.3155684  0.8419834
## 6 -1.7371238 -2.0371910</code></pre>
<pre class="r"><code>str(Portfolio)</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  2 variables:
##  $ X: num  -0.895 -1.562 -0.417 1.044 -0.316 ...
##  $ Y: num  -0.235 -0.885 0.272 -0.734 0.842 ...</code></pre>
<pre class="r"><code># функция для вычисления искомого параметра
alpha.fn &lt;- function(data, index){
  X = data$X[index]
  Y = data$Y[index]
  (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2*cov(X, Y))
}
# рассчитать alpha по всем 100 наблюдениям
alpha.fn(Portfolio, 1:100)</code></pre>
<pre><code>## [1] 0.5758321</code></pre>
<pre class="r"><code># создать бутстреп-выборку и повторно вычислить alpha
set.seed(1)
alpha.fn(Portfolio, sample(100, 100, replace = T))</code></pre>
<pre><code>## [1] 0.5963833</code></pre>
<pre class="r"><code># теперь -- многократное повторение предыдущей операции
boot(Portfolio, alpha.fn, R = 1000)</code></pre>
<pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Portfolio, statistic = alpha.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##      original        bias    std. error
## t1* 0.5758321 -7.315422e-05  0.08861826</code></pre>
<p>Бутстреп повторяет расчёт параметра много раз, делая повторные выборки из наших 100 наблюдений. В итоге этим методом можно вычислить стандартную ошибку параметра, не опираясь на допущения о законе распределении параметра. В нашем случае <span class="math inline">\(\alpha = 0.576\)</span> со стандартной ошибкой <span class="math inline">\(s_{\hat{\alpha}} = 0.089\)</span>.</p>
</div>
<div id="---" class="section level3">
<h3>Точность оценки параметра регрессии</h3>
<p>При построении модели регрессии проблемы в остатках приводят к неверной оценке ошибок параметров. Обойти эту проблему можно, применив для расчёта этих ошибок бутстреп.</p>
<pre class="r"><code># Оценивание точности линейной регрессионной модели ----------------------------
# оценить стандартные ошибки параметров модели 
#  mpg = beta_0 + beta_1 * horsepower с помощью бутстрепа,
#  сравнить с оценками ошибок по МНК
# функция для расчёта коэффициентов ПЛР по выборке из данных
boot.fn &lt;- function(data, index){
  coef(lm(mpg ~ horsepower, data = data, subset = index))
}
boot.fn(Auto, 1:n)</code></pre>
<pre><code>## (Intercept)  horsepower 
##  39.9358610  -0.1578447</code></pre>
<pre class="r"><code># пример применения функции к бутстреп-выборке
set.seed(1)
boot.fn(Auto, sample(n, n, replace = T))</code></pre>
<pre><code>## (Intercept)  horsepower 
##  38.7387134  -0.1481952</code></pre>
<pre class="r"><code># применяем функцию boot для вычисления стандартных ошибок параметров
#  (1000 выборок с повторами)
boot(Auto, boot.fn, 1000)</code></pre>
<pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Auto, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##       original        bias    std. error
## t1* 39.9358610  0.0296667441 0.860440524
## t2* -0.1578447 -0.0003113047 0.007411218</code></pre>
<pre class="r"><code># сравним с МНК
attach(Auto)</code></pre>
<pre><code>## The following object is masked from package:ggplot2:
## 
##     mpg</code></pre>
<pre><code>## The following objects are masked from Auto (pos = 6):
## 
##     acceleration, cylinders, displacement, horsepower, mpg, name,
##     origin, weight, year</code></pre>
<pre class="r"><code>summary(lm(mpg ~ horsepower))$coef</code></pre>
<pre><code>##               Estimate  Std. Error   t value      Pr(&gt;|t|)
## (Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187
## horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81</code></pre>
<pre class="r"><code>detach(Auto)
# оценки отличаются из-за того, что МНК -- параметрический метод с допущениями
# вычислим оценки параметров квадратичной модели регрессии
boot.fn.2 &lt;- function(data, index){
  coef(lm(mpg ~ poly(horsepower, 2), data = data, subset = index))
}
# применим функцию к 1000 бутсреп-выборкам
set.seed(1)
boot(Auto, boot.fn, 1000)</code></pre>
<pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Auto, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##       original        bias    std. error
## t1* 39.9358610  0.0269563085 0.859851825
## t2* -0.1578447 -0.0002906457 0.007402954</code></pre>
<p>В модели регрессии, для которой проводился расчёт, похоже, не нарушаются требования к остаткам, и оценки стандартных ошибок параметров, рассчитанные по МНК, очень близки к ошибкам этих же параметров, полученных бутстрепом.</p>
<p><em>Literature</em></p>
<ol style="list-style-type: decimal">
<li><em>James G., Witten D., Hastie T. and Tibshirani R.</em> An Introduction to Statistical Learning with Applications in R. URL: <a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf">http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf</a></li>
</ol>
</div>
</div>
