<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bootstrap | Mark Goldberg</title>
    <link>/tags/bootstrap/</link>
      <atom:link href="/tags/bootstrap/index.xml" rel="self" type="application/rss+xml" />
    <description>Bootstrap</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019</copyright><lastBuildDate>Fri, 02 Aug 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/logo.png</url>
      <title>Bootstrap</title>
      <link>/tags/bootstrap/</link>
    </image>
    
    <item>
      <title>Cross-validation and bootstrap</title>
      <link>/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#validation-sample&#34;&gt;Validation sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#leave-one-out-cross-validation-loocv&#34;&gt;Leave-one-out cross-validation (LOOCV)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#k-cross-validation&#34;&gt;k-cross-validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bootstrap&#34;&gt;Bootstrap&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#presition-estimation-of-model-parameter&#34;&gt;Presition estimation of model parameter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#---&#34;&gt;Точность оценки параметра регрессии&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;From the following examples we will learn wow to estimate model precision by cross-validation, validation sample and leave-one-out cross-validation (LOOCV).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Model&lt;/em&gt;: linear regression, kNN &lt;em&gt;Dataset&lt;/em&gt;: &lt;code&gt;Auto {ISLR}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We want to build models and compare this models:&lt;br /&gt;
mpg ~ f(horsepower) &lt;code&gt;Auto&lt;/code&gt; dataset, where&lt;br /&gt;
&lt;strong&gt;mpg&lt;/strong&gt; - miles per gallon&lt;br /&gt;
&lt;strong&gt;horsepower&lt;/strong&gt; - engine horsepower&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;#39;ISLR&amp;#39;)        # datasets Auto
attach(Auto)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(horsepower, mpg,
     xlab = &amp;#39;horsepower&amp;#39;, ylab = &amp;#39;mpg&amp;#39;, pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4),
     bg = rgb(0, 0, 1, alpha = 0.4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;validation-sample&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Validation sample&lt;/h3&gt;
&lt;p&gt;Split data to train and test sets and build model using train data.&lt;/p&gt;
&lt;p&gt;Make random vector for data subsetting:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- nrow(Auto)         # number of observation
train.percent &amp;lt;- 0.5    # portion of train data

# split data into train and test
set.seed(1)
inTrain &amp;lt;- sample(n, n*train.percent)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plot data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot train data
par(mar = c(4, 4, 0.5, 1))
plot(horsepower[inTrain], mpg[inTrain],
     xlab = &amp;#39;horsepower&amp;#39;, ylab = &amp;#39;mpg&amp;#39;, pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
# add test data
points(horsepower[-inTrain], mpg[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4))
legend(&amp;#39;topright&amp;#39;, pch = c(16, 16), col = c(&amp;#39;blue&amp;#39;, &amp;#39;red&amp;#39;), legend = c(&amp;#39;test&amp;#39;, &amp;#39;train&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s buld models for train data using &lt;strong&gt;polynomial linear regression&lt;/strong&gt; using vaious polinomial degrees and estimate MSE for each of these models using test data:&lt;br /&gt;
1. &lt;strong&gt;Linear&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower\)&lt;/span&gt;.&lt;br /&gt;
2. &lt;strong&gt;Squared&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2\)&lt;/span&gt;.&lt;br /&gt;
3. &lt;strong&gt;Cubic&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2 + \hat{\beta}_3 \cdot horsepower^3\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- lapply(1:3, function(n) {
  fit.lm &amp;lt;- lm(mpg ~ poly(horsepower, n), data=Auto, subset=inTrain)
  })

# keep MSE for each model
err.test &amp;lt;- sapply(1:3, function(n) {
  mean((mpg[-inTrain] - predict(models[[n]], Auto[-inTrain, ]))^2)
})
names(err.test) &amp;lt;- c(&amp;#39;lm1&amp;#39;, &amp;#39;lm2&amp;#39;, &amp;#39;lm3&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Q: Do our modeles fit the formulas shown before?&lt;/p&gt;
&lt;p&gt;Plot models&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mar = c(4, 4, 0.5, 1))
plot(horsepower[inTrain], mpg[inTrain],
     xlab = &amp;#39;horsepower&amp;#39;, ylab = &amp;#39;mpg&amp;#39;, pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
# add test data
points(horsepower[-inTrain], mpg[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4))

colors=c(&amp;#39;black&amp;#39;, &amp;#39;blue&amp;#39;, &amp;#39;red&amp;#39;)
x1 &amp;lt;- data.frame(horsepower=seq(min(horsepower), max(horsepower), length = 200))
for (i in 1:3) {
    y2 &amp;lt;- predict(models[[i]], newdata=x1)
    lines(x1$horsepower, y2, col=colors[i], lwd=c(2,2,2))
}
legend(&amp;#39;topright&amp;#39;, lty=c(1,1,1),
       col = c(&amp;#39;black&amp;#39;, &amp;#39;blue&amp;#39;, &amp;#39;red&amp;#39;),
       legend = c(&amp;#39;x&amp;#39;, &amp;#39;x^2&amp;#39;, &amp;#39;x^3&amp;#39;), lwd=c(2,2,2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/drafts/cross_validation_bootstrap/cross_validation_bootstrap_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;leave-one-out-cross-validation-loocv&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Leave-one-out cross-validation (LOOCV)&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;#39;GGally&amp;#39;)      # matrix diagrams
library(&amp;#39;boot&amp;#39;)        # cross-validation&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model for train data
fit.glm &amp;lt;- glm(mpg ~ horsepower, data = Auto)
# LOOCV-error
cv.err &amp;lt;- cv.glm(Auto, fit.glm)
cv.err$delta[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 24.23151&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Estimate the precision of polynomial models by changing power.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vector of LOOCV-errors
cv.err.loocv &amp;lt;- rep(0, 5)
names(cv.err.loocv) &amp;lt;- 1:5
# repeat by powers of polynomes
for (i in 1:5){
  fit.glm &amp;lt;- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.loocv[i] &amp;lt;- cv.glm(Auto, fit.glm)$delta[1]
}
# result
cv.err.loocv&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2        3        4        5 
## 24.23151 19.24821 19.33498 19.42443 19.03321&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;k-cross-validation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;k-cross-validation&lt;/h3&gt;
&lt;p&gt;K-times cross-validation is a compromize between sample validation and LOOCV. It is computationally more effective than LOOCV but not so presize.&lt;br /&gt;
We will make 10-time validation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv.err.k.fold &amp;lt;- rep(0, 5)
names(cv.err.k.fold) &amp;lt;- 1:5
# repeat for power of polynomes
for (i in 1:5){
  fit.glm &amp;lt;- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.k.fold[i] &amp;lt;- cv.glm(Auto, fit.glm,
                             K = 10)$delta[1]
}
# result
cv.err.k.fold&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2        3        4        5 
## 24.19329 19.29416 19.49610 19.61828 19.15289&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare with previous result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;err.test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      lm1      lm2      lm3 
## 26.14142 19.82259 19.78252&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Опираясь на результаты расчётов с кросс-валидацией, можно заключить, что на самом деле ошибка вне выборки у линейной модели выше, чем показывала MSE на тестовой выборке. А модели со степенями 2 и 3 на самом деле точнее, чем показывала MSE без перекрёстной проверки.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bootstrap&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bootstrap&lt;/h2&gt;
&lt;div id=&#34;presition-estimation-of-model-parameter&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Presition estimation of model parameter&lt;/h3&gt;
&lt;p&gt;Пример с инвестиционным портфелем из двух активов: &lt;code&gt;Portfolio {ISLR}&lt;/code&gt;. В наборе данных две переменных: * &lt;code&gt;X&lt;/code&gt; – income from X,&lt;br /&gt;
* &lt;code&gt;Y&lt;/code&gt; – income from Y.&lt;br /&gt;
We have &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, the portion of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. Min of income dispersion:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mathrm{Var}(\alpha X + (1 - \alpha) Y) \rightarrow \mathrm{min}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;– parameter:&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[
\alpha = \frac{\sigma_Y^2 - \sigma_{XY}}{\sigma_X^2 + \sigma_Y^2 - 2\sigma_{XY}}
\]&lt;/span&gt; Данных для оценки &lt;span class=&#34;math inline&#34;&gt;\(\hat{\sigma_X^2}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat{\sigma_Y^2}\)&lt;/span&gt; и &lt;span class=&#34;math inline&#34;&gt;\(\hat{\sigma_{XY}}\)&lt;/span&gt; немного (100 наблюдений), поэтому применим бутстреп.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(Portfolio)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            X          Y
## 1 -0.8952509 -0.2349235
## 2 -1.5624543 -0.8851760
## 3 -0.4170899  0.2718880
## 4  1.0443557 -0.7341975
## 5 -0.3155684  0.8419834
## 6 -1.7371238 -2.0371910&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(Portfolio)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    100 obs. of  2 variables:
##  $ X: num  -0.895 -1.562 -0.417 1.044 -0.316 ...
##  $ Y: num  -0.235 -0.885 0.272 -0.734 0.842 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# функция для вычисления искомого параметра
alpha.fn &amp;lt;- function(data, index){
  X = data$X[index]
  Y = data$Y[index]
  (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2*cov(X, Y))
}
# рассчитать alpha по всем 100 наблюдениям
alpha.fn(Portfolio, 1:100)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5758321&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# создать бутстреп-выборку и повторно вычислить alpha
set.seed(1)
alpha.fn(Portfolio, sample(100, 100, replace = T))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5963833&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# теперь -- многократное повторение предыдущей операции
boot(Portfolio, alpha.fn, R = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Portfolio, statistic = alpha.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##      original        bias    std. error
## t1* 0.5758321 -7.315422e-05  0.08861826&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Бутстреп повторяет расчёт параметра много раз, делая повторные выборки из наших 100 наблюдений. В итоге этим методом можно вычислить стандартную ошибку параметра, не опираясь на допущения о законе распределении параметра. В нашем случае &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.576\)&lt;/span&gt; со стандартной ошибкой &lt;span class=&#34;math inline&#34;&gt;\(s_{\hat{\alpha}} = 0.089\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;---&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Точность оценки параметра регрессии&lt;/h3&gt;
&lt;p&gt;При построении модели регрессии проблемы в остатках приводят к неверной оценке ошибок параметров. Обойти эту проблему можно, применив для расчёта этих ошибок бутстреп.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Оценивание точности линейной регрессионной модели ----------------------------
# оценить стандартные ошибки параметров модели 
#  mpg = beta_0 + beta_1 * horsepower с помощью бутстрепа,
#  сравнить с оценками ошибок по МНК
# функция для расчёта коэффициентов ПЛР по выборке из данных
boot.fn &amp;lt;- function(data, index){
  coef(lm(mpg ~ horsepower, data = data, subset = index))
}
boot.fn(Auto, 1:n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (Intercept)  horsepower 
##  39.9358610  -0.1578447&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# пример применения функции к бутстреп-выборке
set.seed(1)
boot.fn(Auto, sample(n, n, replace = T))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (Intercept)  horsepower 
##  38.7387134  -0.1481952&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# применяем функцию boot для вычисления стандартных ошибок параметров
#  (1000 выборок с повторами)
boot(Auto, boot.fn, 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Auto, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##       original        bias    std. error
## t1* 39.9358610  0.0296667441 0.860440524
## t2* -0.1578447 -0.0003113047 0.007411218&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# сравним с МНК
attach(Auto)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from package:ggplot2:
## 
##     mpg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from Auto (pos = 6):
## 
##     acceleration, cylinders, displacement, horsepower, mpg, name,
##     origin, weight, year&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(mpg ~ horsepower))$coef&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               Estimate  Std. Error   t value      Pr(&amp;gt;|t|)
## (Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187
## horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;detach(Auto)
# оценки отличаются из-за того, что МНК -- параметрический метод с допущениями
# вычислим оценки параметров квадратичной модели регрессии
boot.fn.2 &amp;lt;- function(data, index){
  coef(lm(mpg ~ poly(horsepower, 2), data = data, subset = index))
}
# применим функцию к 1000 бутсреп-выборкам
set.seed(1)
boot(Auto, boot.fn, 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Auto, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##       original        bias    std. error
## t1* 39.9358610  0.0269563085 0.859851825
## t2* -0.1578447 -0.0002906457 0.007402954&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;В модели регрессии, для которой проводился расчёт, похоже, не нарушаются требования к остаткам, и оценки стандартных ошибок параметров, рассчитанные по МНК, очень близки к ошибкам этих же параметров, полученных бутстрепом.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Literature&lt;/em&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;em&gt;James G., Witten D., Hastie T. and Tibshirani R.&lt;/em&gt; An Introduction to Statistical Learning with Applications in R. URL: &lt;a href=&#34;http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf&#34;&gt;http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
