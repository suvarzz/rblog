<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cross-validation | Mark Goldberg</title>
    <link>/tags/cross-validation/</link>
      <atom:link href="/tags/cross-validation/index.xml" rel="self" type="application/rss+xml" />
    <description>Cross-validation</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019</copyright><lastBuildDate>Sat, 03 Aug 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/logo.png</url>
      <title>Cross-validation</title>
      <link>/tags/cross-validation/</link>
    </image>
    
    <item>
      <title>Resampling methods</title>
      <link>/post/statistics/resampling_methods/resampling_methods/</link>
      <pubDate>Sat, 03 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/statistics/resampling_methods/resampling_methods/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#validation-approach&#34;&gt;Validation approach&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#leave-one-out-cross-validation-loocv&#34;&gt;Leave-one-out cross-validation (LOOCV)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#k-fold-cross-validation&#34;&gt;k-fold cross validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bootstrapping&#34;&gt;Bootstrapping&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#bibiography&#34;&gt;Bibiography&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;validation-approach&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Validation approach&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Validation&lt;/strong&gt; (hold-out) approach estimates the prediction error of our predictive models. This involves randomly dividing the available set of observations into two parts, a &lt;strong&gt;training set&lt;/strong&gt; and a &lt;strong&gt;testing set&lt;/strong&gt; (validation set). Our statistical model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set. The resulting validation set error rate (typically assessed using &lt;strong&gt;MSE&lt;/strong&gt; in the case of a quantitative response) provides an estimate of the test error rate.&lt;br /&gt;
The drawback of the method is that the &lt;strong&gt;test error rate&lt;/strong&gt; can vary depending on training set.&lt;/p&gt;
&lt;p&gt;Let’s buld &lt;strong&gt;polinomial models&lt;/strong&gt; for first 10 degrees to predict &lt;strong&gt;mpg&lt;/strong&gt; from &lt;strong&gt;horsepower&lt;/strong&gt; dataset (&lt;code&gt;ISLR::Auto&lt;/code&gt;), where &lt;strong&gt;mpg&lt;/strong&gt; - miles per gallon and &lt;strong&gt;horsepower&lt;/strong&gt; - engine horsepower.&lt;br /&gt;
Let’s buld models for train data using &lt;strong&gt;polynomial linear regression&lt;/strong&gt; using vaious polinomial degrees and estimate MSE for each of these models using test data:&lt;br /&gt;
1. &lt;strong&gt;Linear&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower\)&lt;/span&gt;.&lt;br /&gt;
2. &lt;strong&gt;Squared&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2\)&lt;/span&gt;.&lt;br /&gt;
3. &lt;strong&gt;Cubic&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\hat{mpg} = \hat{\beta}_0 + \hat{\beta}_1 \cdot horsepower + \hat{\beta}_2 \cdot horsepower^2 + \hat{\beta}_3 \cdot horsepower^3\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;#39;ISLR&amp;#39;)        # datasets Auto
attach(Auto)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
# split data into train (0.6) and test (0.4)
inTrain &amp;lt;- sample(nrow(Auto), nrow(Auto)*0.6)
train &amp;lt;- Auto[inTrain, ]
test &amp;lt;- Auto[!inTrain, ]

# Buld polynomial models for first ten degrees
models &amp;lt;- lapply(1:10, function(n) {
  fit.lm &amp;lt;- lm(mpg ~ poly(horsepower, n), data=train)
  })

mse.vec &amp;lt;- sapply(1:10, function(n) {
  mean((mpg[-inTrain] - predict(models[[n]], Auto[-inTrain, ]))^2)
})
# create dataframe to store MSE of our models
mse.df &amp;lt;- data.frame(degree = 1:10, mse = NA)
mse.df$mse &amp;lt;- mse.vec
plot(mse.df, type=&amp;quot;o&amp;quot;, main=&amp;quot;MSE of spline regression models for degrees from 1 to 10&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/resampling_methods/resampling_methods_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;### PLOT with data and first three polynomial models
par(mar = c(4, 4, 0.5, 1))
plot(horsepower[inTrain], mpg[inTrain],
     xlab = &amp;#39;horsepower&amp;#39;, ylab = &amp;#39;mpg&amp;#39;, pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
# add test data
points(horsepower[-inTrain], mpg[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4))

colors=c(&amp;#39;black&amp;#39;, &amp;#39;blue&amp;#39;, &amp;#39;red&amp;#39;)
x1 &amp;lt;- data.frame(horsepower=seq(min(horsepower), max(horsepower), length = 200))
for (i in 1:3) {
    y2 &amp;lt;- predict(models[[i]], newdata=x1)
    lines(x1$horsepower, y2, col=colors[i], lwd=c(2,2,2))
}
legend(&amp;#39;topright&amp;#39;, lty=c(1,1,1),
       col = c(&amp;#39;black&amp;#39;, &amp;#39;blue&amp;#39;, &amp;#39;red&amp;#39;, rgb(0, 0, 1, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4)),
       legend = c(&amp;#39;Linear model&amp;#39;, &amp;#39;Squared model&amp;#39;, &amp;#39;Cubic model&amp;#39;, &amp;#39;train data&amp;#39;, &amp;#39;test data&amp;#39;),
       lwd=c(2,2,2,NA,NA), pch=c(NA,NA,NA,16,16))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/resampling_methods/resampling_methods_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# end PLOT&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;leave-one-out-cross-validation-loocv&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Leave-one-out cross-validation (LOOCV)&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;#39;GGally&amp;#39;)      # matrix diagrams
library(&amp;#39;boot&amp;#39;)        # cross-validation&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model for train data
fit.glm &amp;lt;- glm(mpg ~ horsepower, data = Auto)
# LOOCV-error
cv.err &amp;lt;- cv.glm(Auto, fit.glm)
cv.err$delta[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 24.23151&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Estimate the precision of polynomial models by changing power.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vector of LOOCV-errors
cv.err.loocv &amp;lt;- rep(0, 5)
names(cv.err.loocv) &amp;lt;- 1:5
# repeat by powers of polynomes
for (i in 1:5){
  fit.glm &amp;lt;- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.loocv[i] &amp;lt;- cv.glm(Auto, fit.glm)$delta[1]
}
# result
cv.err.loocv&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2        3        4        5 
## 24.23151 19.24821 19.33498 19.42443 19.03321&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;k-fold-cross-validation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;k-fold cross validation&lt;/h2&gt;
&lt;p&gt;K-times cross-validation is a compromize between sample validation and LOOCV. It is computationally more effective than LOOCV but not so presize.&lt;br /&gt;
We will make 10-time validation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv.err.k.fold &amp;lt;- rep(0, 5)
names(cv.err.k.fold) &amp;lt;- 1:5
# repeat for power of polynomes
for (i in 1:5){
  fit.glm &amp;lt;- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.k.fold[i] &amp;lt;- cv.glm(Auto, fit.glm,
                             K = 10)$delta[1]
}
# result
cv.err.k.fold&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2        3        4        5 
## 24.45600 19.29844 19.38499 19.44170 19.29083&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare with previous result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mse.df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    degree      mse
## 1       1 27.00389
## 2       2 20.21120
## 3       3 20.16025
## 4       4 20.24898
## 5       5 19.72873
## 6       6 19.57046
## 7       7 19.40368
## 8       8 20.02701
## 9       9 21.24304
## 10     10 21.11673&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Results show that error of liniear model is higher that was shown by MSE and errors are lower for polynomial regression models n=2,3.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bootstrapping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bootstrapping&lt;/h2&gt;
&lt;p&gt;One of the great advantages of the bootstrap approach is that it can be applied in almost all situations. No complicated mathematical calculations are required. Performing a bootstrap analysis in R entails only two steps. First, we must create a function that computes the statistic of interest. Second, we use the &lt;code&gt;boot()&lt;/code&gt; function, which is part of the boot library, to perform the bootstrap by repeatedly sampling observations from the data set with replacement.&lt;br /&gt;
Lets apply bootstrap for calculation of residual errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot.fn &amp;lt;- function(data, index){
  coef(lm(mpg ~ horsepower, data = data, subset = index))
}
boot.fn(Auto, 1:n)

set.seed(1)
boot.fn(Auto, sample(n, n, replace = T))
# aply boot to calculate standard errors for 1000 samplings with repeats)
boot(Auto, boot.fn, 1000)
# compere with &amp;#39;МНК&amp;#39;
#summary(lm(mpg ~ horsepower))$coef
# оценки отличаются из-за того, что МНК -- параметрический метод с допущениями
# вычислим оценки параметров квадратичной модели регрессии
boot.fn.2 &amp;lt;- function(data, index){
  coef(lm(mpg ~ poly(horsepower, 2), data = data, subset = index))
}
# apply bootstap with 1000 samplings
set.seed(1)
boot(Auto, boot.fn, 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Regression models errors calculated by MHK are similar byb errors calculated using bootstap&lt;/p&gt;
&lt;div id=&#34;bibiography&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bibiography&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://faculty.marshall.usc.edu/gareth-james/&#34;&gt;An Introduction to Statistical Learning by Gareth James&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://afit-r.github.io&#34;&gt;Air Forse Institute of Technology&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
